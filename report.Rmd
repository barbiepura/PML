---
title: "Project - Practical Machine Learning"
author: "Pura Chen"

---

Nowaday, wearable devices has become a very popular thechnology for people to keep track of their health. The goal of this project is to use data extracted from from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict how well they perform in those activities. The variable 'classe' in training set indicates the level of testers performance. We will use cross validation to pick an appropriate model for the prediction.

###Data Analysis

**Load Data**
```{r, cache=TRUE}
setwd("/Users/Pura/Desktop/CourseraR/Machine Learning/project/data")
training<-read.csv("pml-training.csv")
testing<-read.csv("pml-testing.csv")
dim(training)
```

**Data Partition for Validation Set**
```{r, cache=TRUE}
suppressMessages(library(caret))
suppressMessages(library(rpart))
inTrain<-createDataPartition(training$classe, p=0.6, list = FALSE)
myTrain<-training[inTrain, ]
myTest<-training[-inTrain, ]
dim(myTrain)
```

**pre-Proessing**

Since the large size of data will reduce the speed of computation, we will filter out unnecessary variables 

**Remove Near-zero Variance Variables**

```{r, cache = TRUE}
preProc<-preProcess(myTrain, method = c("nzv", "zv"))
myTrain<-predict(preProc, myTrain)
myTest<-predict(preProc, myTest)
testing<-predict(preProc, testing)
dim(myTrain)
```

**Remove variables with mostly NAs**

```{r, cache=TRUE}
MostNA <- sapply(myTrain, function(x) mean(is.na(x))) > 0.90
myTrain<-myTrain[, MostNA==F]
myTest<-myTest[, MostNA==F]
testing<-testing[, MostNA==F]
```

**Principal Component Analysis**
```{r, cache=TRUE}
preProc<-preProcess(myTrain,method = "pca")

myTrain<-predict(preProc, myTrain)
myTest<-predict(preProc, myTest)
testing<-predict(preProc, testing)

firstCol<-which(colnames(myTrain)=="classe")
lastCol<-ncol(myTrain)
myTrain<-myTrain[, firstCol: lastCol]
myTest<-myTest[, firstCol: lastCol]
testing<-testing[, firstCol: lastCol]

```
###Model Fitting

We will use k-fold cross validation method in the model fitting to make sure the best model is selected

```{r, cache=TRUE}
set.seed(328)

trControl<-trainControl(method = "cv", number = 3)
Fit_tree<-train(classe~., method = "rpart", trControl = trControl, data = myTrain)
print(Fit_tree$finalModel)
pred_tree<-predict(Fit_tree, myTest)
length(pred_tree)
confusionMatrix(myTest$classe, pred_tree)
```

```{r, cache=TRUE}
set.seed(328)

trControl<-trainControl(method = "cv", number = 3)
Fit_rf<-train(classe~., method = "rf", trControl = trControl, data = myTrain)
print(Fit_rf$finalModel)
pred_rf<-predict(Fit_rf, myTest)
confusionMatrix(myTest$classe, pred_rf)
```
Apparently random forest provides better result.

###Prediction

```{r, cache=TRUE}
result<-predict(Fit_rf, testing)
```





